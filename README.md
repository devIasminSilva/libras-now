![banner](https://github.com/devIasminSilva/libras-gesture-recognition/assets/143299286/a27fc15b-e38d-42a0-ad23-420e7d131adb)

> Status: Complete âœ…

This is a project that uses deep learning to recognize real-time gestures of the Brazilian Sign Language (Libras) alphabet. Implemented in Python, it makes use of libraries such as MediaPipe, OpenCV, TensorFlow, and Keras.

## Preview

![preview](https://github.com/devIasminSilva/libras-gesture-recognition/assets/143299286/a08a7466-500b-489f-add2-d0d4ff78a801)

## Getting Started

### Prerequisites:

1. OpenCV
   ```
   pip install opencv-python
   ```
2. MediaPipe
   ```
   pip install mediapipe
   ```
3. Keras
   ```
   pip install keras
   ```


### Installation

1. Clone this repository:
   ```
   git clone https://github.com/devIasminSilva/libras-gesture-recognition.git
   ```
2. Navigate to the project directory:
   ```
   cd libras-gesture-recognition
   ```
3. Run the application:
   ```
   python main.py
   ```

## License
This project is distributed under the MIT License. See the `LICENSE` file for more details.
